{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "#녹화한 영상을 저장할 디렉토리 생성\n",
    "OUT_DIR = 'cartpole-experiment'\n",
    "#마지막 몇 개의 Score를 평균을 내서 활용할지\n",
    "MAX_SCORE_QUEUE_SIZE = 100\n",
    "#게임 종류\n",
    "GAME ='CartPole-v0'\n",
    "\n",
    "def get_options():\n",
    "    parser = AgumentParser()\n",
    "    parser.add_argument('--MAX_EPISODE',type=int,default=3000,\n",
    "                        help=\"max number of episodes iteration\")\n",
    "    \n",
    "    parser.add_argument('--ACTION_DIM', type=int, default=2,\n",
    "                        help='number of actions one can take')\n",
    "    \n",
    "    parser.add_argument('--OBSERVATION_DIM', type=int, default=4,\n",
    "                        help='number of observations one can see')\n",
    "    \n",
    "    parser.add_argument('--GAMMA', type=float, default=0.9,\n",
    "                        help='discount factor of Q learning')\n",
    "    \n",
    "    parser.add_argument('--INIT_EPS', type=float, default=1.0,\n",
    "                        help='initial probability for randomly sampling action')\n",
    "    \n",
    "    parser.add_argument('--FINAL_EPS', type=float, default=1e-5,\n",
    "                        help='finial probability for randomly sampling action')\n",
    "    \n",
    "    parser.add_argument('--EPS_DECAY', type=float, default=0.95\n",
    "                        ,help='epsilon decay rate')\n",
    "    \n",
    "    parser.add_argument('--EPS_ANNEAL_STEPS', type=int, default=10,\n",
    "                        help='steps interval to decay epsilon')\n",
    "    \n",
    "    parser.add_argument('--LR', type=float, default=1e-4,\n",
    "                        help='learning rate')\n",
    "    \n",
    "    parser.add_argument('--MAX_EXPERIENCE', type=int, default=2000,\n",
    "                        help='size of experience replay memory')\n",
    "    \n",
    "    parser.add_argument('--BATCH_SIZE', type=int, default=256,\n",
    "                        help='mini batch size')\n",
    "    \n",
    "    parser.add_argument('--H1_SIZE', type=int, default=128,\n",
    "                        help='size of hidden layer 1')\n",
    "    \n",
    "    parser.add_argument('--H2_SIZE', type=int, default=128,\n",
    "                        help='size of hidden layer 2')\n",
    "    \n",
    "    parser.add_argument('--H3_SIZE', type=int, default=128,\n",
    "                        help='size of hidden layer 3')\n",
    "    \n",
    "    options = parser.parse_args()\n",
    "    \n",
    "    return options\n",
    "\n",
    "#hidden layer는 총 3개, 각 layer 128개의 node들로 구성, 2개는 ReLu함수 마지막 output은 함수 tf의 Squeeze함수사용\n",
    "\n",
    "class QAjent:\n",
    "    \n",
    "    def __init__(self,option):\n",
    "        \n",
    "        #3개의 히든 layer 갖게 만듦\n",
    "        #default로 각각 128개의 hidden unit을 갖게 됨\n",
    "        \n",
    "        self.W1=self.weight_variable([options.OBSERVATION_DIM,options.H1_SIZE])\n",
    "        self.b1=self.bias_variable([options.H1_SIZE])\n",
    "        self.W2=self.weight_variable([options.H1_SIZE,options.H2_SIZE])\n",
    "        self.b2=self.bias_variable([options.H2_SIZE])\n",
    "        self.W3=self.weight_variable([options.H3_SIZE,options.H3_SIZE])      \n",
    "        self.W4=self.weight_variable([options.H3_SIZE,options.ACTION_DIM])\n",
    "        self.b4=self.bias_variable([options.ACTION_DIM])\n",
    "        \n",
    "    #W1,W2,W3의 행렬들을 초기화 해주는 단계    \n",
    "    def xavier_initializer(self,shape):\n",
    "        dim_sum =np.sum(shape)\n",
    "        if len(shape)==1:\n",
    "            dim_sum+=1\n",
    "        bound = np.sqrt(6.0/dim_sum)\n",
    "        #tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.dtypes.float32, seed=None, name=None)\n",
    "        return tf.random.uniform(shape,minval=-bound,maxval=bound)\n",
    "    \n",
    "    def weight_variable(self,shape):\n",
    "        return tf.Variable(self.xavier_initializer(shape))\n",
    "    \n",
    "    def bias_variable(self,shape):\n",
    "        return tf.Variable(self.xavier_initializer(shape))\n",
    "    \n",
    "    #nn 세부사항 정의 , 마지막에는 squeeze, 나머지는 relu 함수 이용\n",
    "    def add_value_net(self,options):\n",
    "        observation = tf.placeholder(tf.float32,[None,options.OBSERVATION_DIM])\n",
    "        \n",
    "        h3 = tf.nn.relu(tf.matmul(h2,self.W3)+self.b3)\n",
    "        Q = tf.squeeze(tf.matmul(h3,self.W4)+self.b4)\n",
    "        return observation,Q\n",
    "    \n",
    "    #Q,feed,eps,options를 받아와서 action을 정해줌\n",
    "    #처음 epsilon은 1\n",
    "    def sample_action(self,Q,feed,eps,options):\n",
    "        act_values=Q.eval(feed_dict=deed)\n",
    "        \n",
    "        if random.random() <= eps:\n",
    "            #eps값보다 작으면 action범위 내에값을 하나 뽑아줌\n",
    "            action_index =random.randrange(options.ACTION_DIM)\n",
    "            \n",
    "        else:\n",
    "            #index 최대값, Q_value중 좀 더 큰 값을 갖는 action을 선택\n",
    "            action_index = np.argmax(act_values)\n",
    "        \n",
    "        action = np.zeros(options.ACTION_DIM)\n",
    "        action[action_index]=1\n",
    "        return action\n",
    "    \n",
    "    \n",
    "    \n",
    "def train(env):\n",
    "    \n",
    "    options = get_obtions()\n",
    "    agent =QAgent(options)\n",
    "    sess = tf.compat.v1.InteractiveSession()\n",
    "    \n",
    "    obs, Q1 = agent.add_value_net(options)\n",
    "    act = tf.placeholder(tf.float32, [None, options.ACTION_DIM])\n",
    "    rwd = tf.placeholder(tf.float32, [None, ])\n",
    "    next_obs,Q2 = agent.add_value_net(options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
