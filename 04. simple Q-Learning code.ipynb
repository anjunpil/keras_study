{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled30.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZf2NDDYaGupiRPePoBajy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjunpil/keras_study/blob/master/simple%20Q-Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF3J7vROrkCK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "f5270e67-5b95-40af-e7c0-6c94fe789305"
      },
      "source": [
        "import gym\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from gym.envs.registration import register\n",
        "\n",
        "dir(register)\n",
        "\n",
        "register(id='FrozenLake-v3',\n",
        "         entry_point= 'gym.envs.toy_text:FrozenLakeEnv',\n",
        "         kwargs={'map_name':'4x4','is_slippery':False})\n",
        "\n",
        "env= gym.make('FrozenLake-v3')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-92e0fbf8ae5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m register(id='FrozenLake-v3',\n\u001b[1;32m      9\u001b[0m          \u001b[0mentry_point\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'gym.envs.toy_text:FrozenLakeEnv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m          kwargs={'map_name':'4x4','is_slippery':False})\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FrozenLake-v3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, id, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_specs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot re-register id: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_specs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnvSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: Cannot re-register id: FrozenLake-v3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GktJtAD83KUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b367865e-bd0b-4dac-aba3-bad19269ef27"
      },
      "source": [
        "import gym\n",
        "env = gym.make(\"FrozenLake-v0\")\n",
        "\n",
        "#0 값으로 초기화 시켜줌\n",
        "observation = env.reset()\n",
        "\n",
        "for _ in range(100):\n",
        "  env.render() #출력\n",
        "  action = env.action_space.sample() # agent 의 action\n",
        "  #print(action) #0은 left /1은 down/ 2는 right/ 3은 up\n",
        "  observation,reward,done,info = env.step(action)\n",
        "  print(f\"observation : {observation}  reward : {reward}\\n done : {done} info : {info}\")\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 0  reward : 0.0\n",
            " done : False info : {'prob': 0.3333333333333333}\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 0  reward : 0.0\n",
            " done : False info : {'prob': 0.3333333333333333}\n",
            "  (Right)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 1  reward : 0.0\n",
            " done : False info : {'prob': 0.3333333333333333}\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 1  reward : 0.0\n",
            " done : False info : {'prob': 0.3333333333333333}\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 2  reward : 0.0\n",
            " done : False info : {'prob': 0.3333333333333333}\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 6  reward : 0.0\n",
            " done : False info : {'prob': 0.3333333333333333}\n",
            "  (Right)\n",
            "SFFF\n",
            "FH\u001b[41mF\u001b[0mH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 2  reward : 0.0\n",
            " done : False info : {'prob': 0.3333333333333333}\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 1  reward : 0.0\n",
            " done : False info : {'prob': 0.3333333333333333}\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 1  reward : 0.0\n",
            " done : False info : {'prob': 0.3333333333333333}\n",
            "  (Left)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0.0\n",
            " done : True info : {'prob': 0.3333333333333333}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0}\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "observation : 5  reward : 0\n",
            " done : True info : {'prob': 1.0, 'TimeLimit.truncated': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob3vUB2w5S5q",
        "colab_type": "text"
      },
      "source": [
        "## 사용자 입력을 받아 행동하는 게임 실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi-rMqlY3mya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys,tty,termios\n",
        "\n",
        "class _Getch:\n",
        "  \n",
        "  def __call__(self):\n",
        "    fd = sys.stdin.fileno()\n",
        "    old_settings = termios.tcgetattr(fd)\n",
        "\n",
        "    try:\n",
        "      tty.setraw(sys.stdin.fileno())\n",
        "      ch = sys.stdin.read(3)\n",
        "\n",
        "    finally:\n",
        "\n",
        "      termios.tcsetattr(fd,termios.TCSADRAIN,old_settings)\n",
        "    return ch\n",
        "\n",
        "inkey = _Getch()\n",
        "\n",
        "#MACROS\n",
        "\n",
        "LEFT = 0\n",
        "DOWN = 1\n",
        "RIGHT =2\n",
        "UP =3\n",
        "\n",
        "#key를 받는 코드\n",
        "#up키 입력시 \\x1b[A 입력\n",
        "arrow_keys={'\\x1b[A':UP,\n",
        "            '\\x1b[B':DOWN,\n",
        "            '\\x1b[C':RIGHT,\n",
        "            '\\x1b[D':LEFT,\n",
        "            }\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzJMPgGE9i_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "f117e10f-206a-4fc7-d1bc-46851d083205"
      },
      "source": [
        "register(\n",
        "    id='FrozenLakeL-v3',\n",
        "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
        "    kwargs={'map_name' : '4x4', 'is_slippery': False}\n",
        ")\n",
        "\n",
        "env = gym.make('FrozenLakeL-v3')\n",
        "\n",
        "env.render()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-9TQ6LOTy8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while True:\n",
        "  key = inkey()\n",
        "  if key not in arrow_keys.keys():\n",
        "    print(\"Game aborted!\")\n",
        "    break\n",
        "\n",
        "  action =arrow_keys[key]\n",
        "  state,reward,done,info = env.step(action)\n",
        "  env.render()\n",
        "  print(f\"State : {state},Action : {action},Reward : {reward},Info : {info}\")\n",
        "\n",
        "  if done:\n",
        "    print(\"Finished with reward\",reward)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC6tkCigVa0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "env = gym.make(\"FrozenLake-v0\")\n",
        "\n",
        "#0 값으로 초기화 시켜줌\n",
        "observation = env.reset()\n",
        "\n",
        "for _ in range(100):\n",
        "  env.render() #출력\n",
        "  action = env.action_space.sample() # agent 의 action\n",
        "  #print(action) #0은 left /1은 down/ 2는 right/ 3은 up\n",
        "  observation,reward,done,info = env.step(action)\n",
        "  print(f\"observation : {observation}  reward : {reward}\\n done : {done} info : {info}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASiLC_l2ZW2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Q 알고리즘 적용 실습\n",
        "\n",
        "import numpy as np\n",
        "import random as pr\n",
        "\n",
        "\n",
        "# 액션을 정하기 위한 알고리즘을 정의 , Q 테이블의 액션 기대값이 가장 큰 액션을 선택 or 기대값이 0 이라면 random하게 액션을 선택\n",
        "\n",
        "def rargmax(vector):\n",
        "\n",
        "  m = np.amax(vector)\n",
        "  #print(m)\n",
        "  indices = np.nonzero(vector == m )[0]\n",
        "  #print(indices)\n",
        "  return pr.choice(indices)\n",
        "\n",
        "\n",
        "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
        "#env.observation_space.n =16\n",
        "#env.action_space.n =4\n",
        "\n",
        "#테이블 모든 값 초기화\n",
        "rList=[]\n",
        "\n",
        "#파라미터 값 설정\n",
        "num_episodes = 2000\n",
        "\n",
        "for i in range(num_episodes):\n",
        "  state =env.reset()\n",
        "  rAll =0\n",
        "  done = False\n",
        "\n",
        "  # Q learning 알고리즘\n",
        "\n",
        "  while not done:\n",
        "    action = rargmax(Q[state,:])\n",
        "\n",
        "    new_state,reward,done,_ = env.step(action)\n",
        "\n",
        "    Q[state,action] = reward + np.max(Q[new_state,:])\n",
        "\n",
        "    rAll+=reward\n",
        "    state = new_state\n",
        "\n",
        "  rList.append(rAll)\n",
        "\n",
        "# 2000번의 에피소드를 정의하고 에피소드가 끝날 때까지 액션을 취하고 최종 보상값을 리스트에 담는다\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFz7fdsXi4mP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "49a5b656-b1ac-459e-cd13-c0227190de16"
      },
      "source": [
        "print(\"Sucess rate  \" + str(sum(rList)/num_episodes))\n",
        "print(\"Final Q-Table Values\")\n",
        "print(\"LEF DOW RIG UP\")\n",
        "print(Q)\n",
        "\n",
        "#2000qjs episode 목적지까지 도달한 횟수에 대한 확률, 최종 에피소드 까지 완료 후의 Q 테이블값을 출력"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sucess rate  0.0205\n",
            "Final Q-Table Values\n",
            "LEF DOW RIG UP\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhmFegI3l_Jv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3fbe014a-cc9a-4820-ca54-53fadeab3a05"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#성공 횟수를 그래픽으로 출력\n",
        "\n",
        "plt.bar(range(len(rList)),rList,color = \"blue\")\n",
        "plt.show()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
