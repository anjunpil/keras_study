## 근사함수,인공신경망



- 움직이는 장애물과 같은 문제에 강화학습을 적용시키려면, 테이블의 형태로 모든 행동 상태에 대해 업데이트하고 저장하는 방식을 바꿔야 함

- 근사함수 - 기존 데이터를 매개변수를 통해 근사하는 함수(데이터가 비슷하지만 같지는 않다)

- 근사함수를 가치함수로 인공신경망을 사용

<br>

#### 인공신경망

- 인공신경망을 사용하는 이유 - 오래전부터 강화학습에서 ,근사함수로 인공신경망을 사용해 왔음
- 딥러닝 발전 이후 거의 대부분의 경우 근사함수로 인공신경망을 사용

- activation function을 통해 입력을 처리

- 인공신경망 

  - 뉴런 - node
  - 뉴런으로 들어오는 신호 - 입력
  - 입력을 처리하는 함수 - 활성함수
  - 뉴런에서 나가는 정보 - 출력

- 노드로 계층구조(인공신경망)를 만듦, 레이어층

  - 입력층(input layer), 은닉층(hidden layer),출력층(output layer)

  - 항상 입력층에서 출력층으로 흐름

- 시냅스 - 노드를 연결하는 화살표 모양
  - 각 시냅스는 가중치를 가지고 있음
  - 단순히 연결하는 것이 아니라 비중을 조절해 줌

![사진](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/134px-Artificial_neural_network.svg.png)

- 앞층으로부터 3개의 입력을 받는 경우, 노드는 입력을 받아 노드를 가공해 활성함수에 넣음
- 활성함수에 들어가는 입력은 가중치(W)를 곱하고 편향(bias)를 더한 값

#### 활성함수

- ex - ReLu, tanh, sigmoid

##### sigmoid

- 0과 1로 활성과 비활성의 출력을 내지 않고 0과 1사이의 연속적인 값을 출력으로 내놓음

![사진](https://mlnotebook.github.io/img/transferFunctions/sigmoid.png)



##### ReLu

- Rectified Linear Unit의 줄임말
- 입력이 0보다 크면 그대로 출력, 0보다 작으면 0값을 출력

![사진](https://mlnotebook.github.io/img/transferFunctions/relu.png)

- 위 두 함수는 비선형함수
- 선형함수는 층을 넓히고 쌓아봤자 결국 층이 하나
- 비선형 함수의 경우 - 층을 넓히고 쌓을수록 함수는 새로운 형태로 변형
- 2개이상의 은닉층을 가진 신경망 - 심층 신경망



<br>

- 입력이 심층신경망을 통과해서 나온 출력 - 예측
- 학습 데이터의 정답 - 타깃
- 심층신경망을 통과한 예측값과 타깃의 오차를 계산 -> 오차함수(loss function)

- 평균제곱오차(MSE(mean squared error)) - (타깃- 예측)**2
- 오차를 최소화하도록 심층신경망의 가중치와 편향을 업데이트(역전파 알고리즘)

<br>

- 역전파(back-propagation) - 출력에서 계산한 오차로부터 다시 각 가중치와 편향의 오차 기여도를 계산



#### 경사하강법

- 그래프 상에서 미분값은 기울기 혹은 경사

![사진](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F997774505C7738DC02)

경사하강법 - SGD,RMSprop,Adam

모든 경사하강법은 학습 속도라는 변수를 가지고 있음 (한 번 심층신경망을 업데이트할 때 얼마나 업데이트할 것인지 결정하는 계수)

케라스 모델은 인공신경망을 뜻함

케라스는 사용자의 편의를 위해 자주 사용되는 층은 하나의 모듈로서 제공

- 레이블 - 각 이미지가 어떤 분류에 해당하는 지를 숫자로 나타낸 것
- 순서대로 입력으로 들어온 이미지가 레이블 0~9중 하나일 확률을 의미



- 원핫 인코딩 - 전체 집합의 크기와 같은 차원의 벡터에 표현하고 싶은 원소의 인덱스는 1의 값, 다른 인덱스는 0의 값