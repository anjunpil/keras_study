## 용어 정리

#### 1.인공지능 
- 일반적으로 인지과정을 자동화하기 위한 모든 방법

#### 2.머신러닝
- 훈련 데이터를 사용 , 자동으로 모델을 개발하는 AI 하위 분야(데이터를 프로그램으로 -> 학습)

#### 3.딥러닝
- 기하학적 변환 함수들이 번갈아 가며 길게 연결된 모델
- 연산들은 층이란 모듈을 구성
- 층은 학습되는 동안 가중치 파라미터를 가짐
- 가중치에 모델의 지식이 저장됨


#### 4.퍼셉트론
-

#### 


- 딥러닝에서 모든 것은 벡터
- 벡터 - 숫자의 배열
```python
#vector
x = np.array
```

### 5.신경망
- 인공신경망 뉴런은 여러 입력값을 받아 일정 수준 이상이면 활성화 되어 출력값 내보냄


#### 6.머신러닝 작업 흐름
1. 문제를 정의
	- 어떤 데이터를 사용할 수 있고, 예측 대상은 무엇,데이터를 더 많이 모아야 하나, 데이터셋에 레이브릉ㄹ 달기 위해 사람을 고용해야 하나

2. 목표 달성을 축정하기 위해 신뢰할 수 있는 방법을 찾는다,예측 정확도

3. 모델을 평가하기 위한 검증과정 준비,훈련 set, 검증 set,테스트 set

4. 데이터를 벡터화, 신경망에 잘 맞는 형태로 전처리(정규화)

5.머신 러닝이 주어진 문제를 해결 할 수 있는 지 확인

6.하이퍼파라미터를 튜닝 , 규제를 추가하여 모델 구조를 점진적으로 개선

7.하이퍼파라미터 튜닝, 검증 세트에 과대적합됨을 유의, 그 때문에 테스트 set을 따로 떼어 놓음



#### 7.네트워크 구조

- 벡터 데이터 - 완전 연결 네트워크(Dense 층)

- 이미지 데이터 - 2D 컨브넷

- 사운드 데이터 - 1D 컨브넷(권장) or RNN

- 텍스트 데이터 - 1D 컨브넷(권장) or RNN

- 시계열 데이터 - RNN(권장) or 1D 컨브넷

- 다른 종류의 시퀀스 데이터 - RNN이나 1D 컨브넷, 데이터 순서가 중요 -> RNN

- 비디오 데이터 - 3D 컨브넷(연속 동작을 감지할 필요가 있다면)이나 특성 추출을 담당하는 프레임별 2D 컨브넷, 그 뒤를 이어 시퀀스를 처리하는 RNN or 1D 컨브넷의 조합

- 볼륨을 가진 데이터 - 3D 컨브넷

#### 8.완전 연결 네트워크

- 벡터 데이터를 처리하는 Dense층을 쌓은 것
- 한 Dense 층의 유닛이 다른 층의 모든 유닛과 연결되어 있음
- 범주형 데이터에 가장 많이 사용된다
- 이진 분류를 수행하려면 마지막 Dense 층이 하나의 유닛을 가져야 하고 Sigmoid 활성화 함수를 사용해야함
- 손실은 binary_crossentropy를 사용
- targit : 0 or 1
<br>
- 8.1 이진 분류

```python
from keras import models
from keras import layers

model= models.Sequential()

num_input_features=np,arange(6,4)

model.add(layers.Dense(32,activation='relu',input_shape=(num_input_features,)))
model.add(layers.Dense(32,activation='relu'))
model.add(layers.Dense(1,activation='sigmoid'))

model.compile(potimizer='rmsprop',loss='binary_crossentropy')
```
<br>
- 8.2 단일 레이블 다중 분류

마지막 Dense 층이 클래스 개수만큼 유닛을 가져야함
softmax 활성화 함수 사용


```python
model.add(layers.Dense(32,activation='relu',input_shape=(num_input_features,)))
model.add(layers.Dense(32,activation='relu'))
model.add(layers.Dense(num_classed,activation='softmax'))
model.compile(optimizer ='rmsprop',loss = 'categorical_crossentropy'
```
<br>
- 8.3 다중 레이블 다중 분류

마지막 Dense 층이 클래스 개수만큼 유닛을 가져야함
sigmoid 활성화 함수 사용
targit은 k-핫 인코딩(다중 출력을 위해 여러개의 레이블이 1이 될 수 있음)
<br>
사이킷런 MUltiLabelBinarizer 클래스 사용


```python
model = models.Sequential()
model.add(layers.Dense(32,activation='relu', input_shape(num_input_features,)))
model.add(layers.Dense(32,activation='relu')
model.add(layers.Dense(num_classes,activation = 'sigmoid'))

model.compile(optimizer='rmsprop' , loss='binary_crossentropy')
```

#### 9.메타러닝
- "Learning To Learn" 이라고 알려져 있음 , Meta-learning은 몇몇 training 예제를 통해 모델로 하여금,새로운 기술을 배우거나, 새로운 환경에 빠르게 적응할 수 있도록 설계하는것


#### 10.learning rate(학습률)
- 경사하강법 알고리즘은 기울기에 learning rate 또는 step size라 불리는 스칼라를 곱해 다음 지점을 결정
- 너무 크지도 작지도 않은 적절한 학습률을 세팅해야 함
- iteration을 수행할 때, 다음 point를 어느 정도로 옮길지를 결정하는 것
![사진](https://m.blog.naver.com/PostView.nhn?blogId=cattree_studio&logNo=220703210504&proxyReferer=https:%2F%2Fwww.google.com%2F#)

#### 11.entropy
- 최적의 전략 하에 그 사건을 예측하는 데 필요한 질문 개수
- 최적의 전략 하에서 필요한 질문개수의 기대값

#### 12.overfitting
- 학습데이터를 토대로 classifier를 만들 때, classifier가 training data에 너무 잘맞게 되는 것
- test data가 들어올 때 , 성능이 떨어지는 모델이 될 수 있음

#### 13.regularization
![사진](https://m.blog.naver.com/PostView.nhn?blogId=cattree_studio&logNo=220703210504&proxyReferer=https:%2F%2Fwww.google.com%2F#)
- 파란색 그래프를 녹색으로 바꾸는 것
![사진](https://m.blog.naver.com/PostView.nhn?blogId=cattree_studio&logNo=220703210504&proxyReferer=https:%2F%2Fwww.google.com%2F#)
- 1. 코스트 함수의 값은
- 2. 기존의 코스트 값에다가
- 3. lambda라는 regulariztion strength 상수에
- 4. 각 weight들의 제곱의 합을 곱하여 더한 값
- weight가 낮을 수록 overfitting될 확률이 낮아지고 , 녹색선처럼 곡선을 편다 볼 수 있음


```
