{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:   0 | score avg: 37.00 | memory length:   37 | epsilon: 1.0000\n",
      "episode:   1 | score avg: 36.20 | memory length:   66 | epsilon: 1.0000\n",
      "episode:   2 | score avg: 33.98 | memory length:   80 | epsilon: 1.0000\n",
      "episode:   3 | score avg: 36.78 | memory length:  142 | epsilon: 1.0000\n",
      "episode:   4 | score avg: 35.10 | memory length:  162 | epsilon: 1.0000\n",
      "episode:   5 | score avg: 33.59 | memory length:  182 | epsilon: 1.0000\n",
      "episode:   6 | score avg: 33.73 | memory length:  217 | epsilon: 1.0000\n",
      "episode:   7 | score avg: 32.96 | memory length:  243 | epsilon: 1.0000\n",
      "episode:   8 | score avg: 31.66 | memory length:  263 | epsilon: 1.0000\n",
      "episode:   9 | score avg: 31.80 | memory length:  296 | epsilon: 1.0000\n",
      "episode:  10 | score avg: 31.32 | memory length:  323 | epsilon: 1.0000\n",
      "episode:  11 | score avg: 29.89 | memory length:  340 | epsilon: 1.0000\n",
      "episode:  12 | score avg: 29.60 | memory length:  367 | epsilon: 1.0000\n",
      "episode:  13 | score avg: 29.44 | memory length:  395 | epsilon: 1.0000\n",
      "episode:  14 | score avg: 28.99 | memory length:  420 | epsilon: 1.0000\n",
      "episode:  15 | score avg: 27.49 | memory length:  434 | epsilon: 1.0000\n",
      "episode:  16 | score avg: 26.35 | memory length:  450 | epsilon: 1.0000\n",
      "episode:  17 | score avg: 25.31 | memory length:  466 | epsilon: 1.0000\n",
      "episode:  18 | score avg: 25.38 | memory length:  492 | epsilon: 1.0000\n",
      "episode:  19 | score avg: 25.74 | memory length:  521 | epsilon: 1.0000\n",
      "episode:  20 | score avg: 25.17 | memory length:  541 | epsilon: 1.0000\n",
      "episode:  21 | score avg: 24.15 | memory length:  556 | epsilon: 1.0000\n",
      "episode:  22 | score avg: 26.44 | memory length:  603 | epsilon: 1.0000\n",
      "episode:  23 | score avg: 26.49 | memory length:  630 | epsilon: 1.0000\n",
      "episode:  24 | score avg: 25.54 | memory length:  647 | epsilon: 1.0000\n",
      "episode:  25 | score avg: 24.49 | memory length:  662 | epsilon: 1.0000\n",
      "episode:  26 | score avg: 23.64 | memory length:  678 | epsilon: 1.0000\n",
      "episode:  27 | score avg: 22.48 | memory length:  690 | epsilon: 1.0000\n",
      "episode:  28 | score avg: 22.83 | memory length:  716 | epsilon: 1.0000\n",
      "episode:  29 | score avg: 21.65 | memory length:  727 | epsilon: 1.0000\n",
      "episode:  30 | score avg: 21.78 | memory length:  750 | epsilon: 1.0000\n",
      "episode:  31 | score avg: 22.10 | memory length:  775 | epsilon: 1.0000\n",
      "episode:  32 | score avg: 21.09 | memory length:  787 | epsilon: 1.0000\n",
      "episode:  33 | score avg: 21.28 | memory length:  810 | epsilon: 1.0000\n",
      "episode:  34 | score avg: 21.75 | memory length:  836 | epsilon: 1.0000\n",
      "episode:  35 | score avg: 20.98 | memory length:  850 | epsilon: 1.0000\n",
      "episode:  36 | score avg: 20.78 | memory length:  869 | epsilon: 1.0000\n",
      "episode:  37 | score avg: 21.40 | memory length:  896 | epsilon: 1.0000\n",
      "episode:  38 | score avg: 20.96 | memory length:  913 | epsilon: 1.0000\n",
      "episode:  39 | score avg: 19.97 | memory length:  924 | epsilon: 1.0000\n",
      "episode:  40 | score avg: 20.07 | memory length:  945 | epsilon: 1.0000\n",
      "episode:  41 | score avg: 19.46 | memory length:  959 | epsilon: 1.0000\n",
      "episode:  42 | score avg: 18.92 | memory length:  973 | epsilon: 1.0000\n",
      "episode:  43 | score avg: 19.53 | memory length:  998 | epsilon: 1.0000\n",
      "WARNING:tensorflow:Layer dqn_22 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dqn_23 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "episode:  44 | score avg: 21.17 | memory length: 1034 | epsilon: 0.7034\n",
      "episode:  45 | score avg: 20.76 | memory length: 1051 | epsilon: 0.5930\n",
      "episode:  46 | score avg: 19.98 | memory length: 1064 | epsilon: 0.5203\n",
      "episode:  47 | score avg: 19.28 | memory length: 1077 | epsilon: 0.4566\n",
      "episode:  48 | score avg: 18.45 | memory length: 1088 | epsilon: 0.4088\n",
      "episode:  49 | score avg: 17.61 | memory length: 1098 | epsilon: 0.3697\n",
      "episode:  50 | score avg: 21.45 | memory length: 1154 | epsilon: 0.2106\n",
      "episode:  51 | score avg: 21.30 | memory length: 1174 | epsilon: 0.1722\n",
      "episode:  52 | score avg: 22.07 | memory length: 1203 | epsilon: 0.1287\n",
      "episode:  53 | score avg: 21.67 | memory length: 1221 | epsilon: 0.1074\n",
      "episode:  54 | score avg: 23.40 | memory length: 1260 | epsilon: 0.0726\n",
      "episode:  55 | score avg: 26.76 | memory length: 1317 | epsilon: 0.0409\n",
      "episode:  56 | score avg: 26.48 | memory length: 1341 | epsilon: 0.0322\n",
      "episode:  57 | score avg: 29.43 | memory length: 1397 | epsilon: 0.0183\n",
      "episode:  58 | score avg: 31.09 | memory length: 1443 | epsilon: 0.0115\n",
      "episode:  59 | score avg: 31.98 | memory length: 1483 | epsilon: 0.0099\n",
      "episode:  60 | score avg: 32.08 | memory length: 1516 | epsilon: 0.0099\n",
      "episode:  61 | score avg: 36.18 | memory length: 1589 | epsilon: 0.0099\n",
      "episode:  62 | score avg: 43.16 | memory length: 1695 | epsilon: 0.0099\n",
      "episode:  63 | score avg: 52.64 | memory length: 1833 | epsilon: 0.0099\n",
      "episode:  64 | score avg: 71.48 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  65 | score avg: 81.83 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  66 | score avg: 88.35 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  67 | score avg: 97.31 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  68 | score avg: 102.48 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  69 | score avg: 107.13 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  70 | score avg: 115.52 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  71 | score avg: 142.77 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  72 | score avg: 143.89 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  73 | score avg: 149.50 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  74 | score avg: 149.25 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  75 | score avg: 155.83 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  76 | score avg: 154.44 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  77 | score avg: 153.20 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  78 | score avg: 153.58 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  79 | score avg: 154.32 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  80 | score avg: 153.89 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  81 | score avg: 151.50 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  82 | score avg: 157.45 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  83 | score avg: 158.61 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  84 | score avg: 161.24 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  85 | score avg: 159.02 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  86 | score avg: 164.52 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  87 | score avg: 176.67 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  88 | score avg: 183.20 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  89 | score avg: 179.38 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  90 | score avg: 182.24 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  91 | score avg: 180.32 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  92 | score avg: 184.79 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  93 | score avg: 183.41 | memory length: 2000 | epsilon: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  94 | score avg: 181.67 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  95 | score avg: 179.40 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  96 | score avg: 178.46 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  97 | score avg: 175.61 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  98 | score avg: 172.65 | memory length: 2000 | epsilon: 0.0099\n",
      "episode:  99 | score avg: 171.59 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 100 | score avg: 170.63 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 101 | score avg: 167.87 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 102 | score avg: 165.78 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 103 | score avg: 166.20 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 104 | score avg: 164.18 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 105 | score avg: 163.36 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 106 | score avg: 163.33 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 107 | score avg: 162.79 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 108 | score avg: 161.11 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 109 | score avg: 161.00 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 110 | score avg: 165.60 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 111 | score avg: 165.84 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 112 | score avg: 165.96 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 113 | score avg: 166.26 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 114 | score avg: 168.34 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 115 | score avg: 172.00 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 116 | score avg: 177.40 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 117 | score avg: 180.76 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 118 | score avg: 178.89 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 119 | score avg: 178.80 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 120 | score avg: 176.32 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 121 | score avg: 175.19 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 122 | score avg: 173.97 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 123 | score avg: 175.27 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 124 | score avg: 177.24 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 125 | score avg: 174.52 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 126 | score avg: 175.67 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 127 | score avg: 176.90 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 128 | score avg: 176.01 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 129 | score avg: 181.31 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 130 | score avg: 180.08 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 131 | score avg: 179.87 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 132 | score avg: 169.28 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 133 | score avg: 172.16 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 134 | score avg: 177.14 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 135 | score avg: 170.33 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 136 | score avg: 171.69 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 137 | score avg: 174.32 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 138 | score avg: 173.19 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 139 | score avg: 161.97 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 140 | score avg: 162.68 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 141 | score avg: 167.41 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 142 | score avg: 169.77 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 143 | score avg: 171.19 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 144 | score avg: 174.07 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 145 | score avg: 170.26 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 146 | score avg: 171.74 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 147 | score avg: 170.86 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 148 | score avg: 168.38 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 149 | score avg: 169.74 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 150 | score avg: 165.67 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 151 | score avg: 161.10 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 152 | score avg: 164.19 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 153 | score avg: 164.47 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 154 | score avg: 157.72 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 155 | score avg: 152.85 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 156 | score avg: 149.17 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 157 | score avg: 151.75 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 158 | score avg: 155.67 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 159 | score avg: 159.41 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 160 | score avg: 147.07 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 161 | score avg: 147.26 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 162 | score avg: 151.93 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 163 | score avg: 148.54 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 164 | score avg: 152.79 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 165 | score avg: 154.61 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 166 | score avg: 155.85 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 167 | score avg: 166.06 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 168 | score avg: 166.96 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 169 | score avg: 166.66 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 170 | score avg: 172.49 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 171 | score avg: 174.74 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 172 | score avg: 172.57 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 173 | score avg: 181.61 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 174 | score avg: 195.25 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 175 | score avg: 208.93 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 176 | score avg: 204.83 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 177 | score avg: 205.45 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 178 | score avg: 203.91 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 179 | score avg: 210.92 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 180 | score avg: 213.72 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 181 | score avg: 215.45 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 182 | score avg: 220.11 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 183 | score avg: 218.70 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 184 | score avg: 221.83 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 185 | score avg: 223.34 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 186 | score avg: 230.81 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 187 | score avg: 238.13 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 188 | score avg: 251.82 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 189 | score avg: 254.43 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 190 | score avg: 269.89 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 191 | score avg: 274.20 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 192 | score avg: 270.58 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 193 | score avg: 269.32 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 194 | score avg: 265.99 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 195 | score avg: 259.89 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 196 | score avg: 253.60 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 197 | score avg: 248.34 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 198 | score avg: 256.51 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 199 | score avg: 252.36 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 200 | score avg: 260.32 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 201 | score avg: 271.99 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 202 | score avg: 281.39 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 203 | score avg: 275.85 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 204 | score avg: 271.97 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 205 | score avg: 264.87 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 206 | score avg: 260.38 | memory length: 2000 | epsilon: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 207 | score avg: 269.54 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 208 | score avg: 274.99 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 209 | score avg: 277.09 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 210 | score avg: 273.98 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 211 | score avg: 272.88 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 212 | score avg: 266.00 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 213 | score avg: 259.80 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 214 | score avg: 257.52 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 215 | score avg: 264.06 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 216 | score avg: 258.06 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 217 | score avg: 258.95 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 218 | score avg: 266.26 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 219 | score avg: 267.03 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 220 | score avg: 263.83 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 221 | score avg: 263.75 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 222 | score avg: 266.57 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 223 | score avg: 263.51 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 224 | score avg: 268.86 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 225 | score avg: 274.58 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 226 | score avg: 270.42 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 227 | score avg: 269.88 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 228 | score avg: 265.19 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 229 | score avg: 271.17 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 230 | score avg: 273.05 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 231 | score avg: 274.35 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 232 | score avg: 267.91 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 233 | score avg: 264.22 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 234 | score avg: 260.00 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 235 | score avg: 270.10 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 236 | score avg: 268.19 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 237 | score avg: 267.97 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 238 | score avg: 270.27 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 239 | score avg: 261.45 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 240 | score avg: 266.30 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 241 | score avg: 268.97 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 242 | score avg: 280.77 | memory length: 2000 | epsilon: 0.0099\n",
      "episode: 243 | score avg: 302.70 | memory length: 2000 | epsilon: 0.0099\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "\n",
    "#상태가 입력, 큐함수가 출력인 인공신경망 생성\n",
    "#클래스를 두번 호출해서 model,target_model을 생성\n",
    "#하지만 무작위 수를 뽑아 가중치를 초기화 하기 때문에 통일해야 함,update_target_model()로 통일\n",
    "class DQN(tf.keras.Model):\n",
    "    def __init__(self,action_size):\n",
    "        super(DQN,self).__init__()\n",
    "        self.fc1= Dense(24,activation='relu')\n",
    "        self.fc2= Dense(24,activation='relu')\n",
    "        #action_size - 모델의 출력이 큐함수이므로 , 마지막 층의 크기는 행동의 개수가 되어야 함\n",
    "        #RandomUniform 함수는 특정 범위 안에서 무작위 수를 뽑아 가중치를 초기화\n",
    "        self.fc_out = Dense(action_size,\n",
    "                           kernel_initializer = RandomUniform(-1e-3,1e-3))\n",
    "    \n",
    "    \n",
    "    def call(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        q = self.fc_out(x)\n",
    "        return q\n",
    "    \n",
    "#카트폴 예제 DQN \n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self,state_size,action_size):\n",
    "        self.render = False\n",
    "        \n",
    "        #상태와 행동 크기 정의\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        #DQN 하이퍼파라미터\n",
    "        \n",
    "        self.discount_factor =0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon =1.0\n",
    "        self.epsilon_decay =0.99\n",
    "        self.epsilon_min =0.01\n",
    "        self.batch_size = 64\n",
    "        self.train_start =1000\n",
    "        \n",
    "        #리플레이 메모리 ,최대 크기\n",
    "        self.memory= deque(maxlen=2000)\n",
    "        \n",
    "        #모델, 타깃모델 생성\n",
    "        \n",
    "        self.model = DQN(action_size)\n",
    "        self.target_model = DQN(action_size)\n",
    "        self.optimizer = Adam(lr = self.learning_rate)\n",
    "        \n",
    "        #타깃 모델 초기화\n",
    "\n",
    "        self.update_target_model()\n",
    "        \n",
    "    #타깃 모델을 모델의 가중치로 업데이트\n",
    "    #model로 부터 가중치 값을 가져와 target_model의 가중치 값으로 설정\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "    #입실론 탐욕 정책으로 행동 선택\n",
    "    #입실론은 처음에는 1의 값을 가짐, 이때 agent는 무작위로 행동을 선택\n",
    "    #매 step마다 입실론은 감소됨\n",
    "    def get_action(self,state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        else:\n",
    "            q_value = self.model(state)\n",
    "            return np.argmax(q_value[0])\n",
    "        \n",
    "    #샘플 <s,a,r,s` > 을 리플레이 메모리에 저장\n",
    "    \n",
    "    def append_sample(self,state,action,reward,next_state,done):\n",
    "        self.memory.append((state,action,reward,next_state,done))\n",
    "        \n",
    "    #리플레이 메모리에서 무작위로 추출한 배치로 모델 학습\n",
    "    \n",
    "    def train_model(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *=self.epsilon_decay\n",
    "            \n",
    "        #메모리에서 배치 크기만큼 무작위로 샘플 추출\n",
    "        mini_batch = random.sample(self.memory,self.batch_size)\n",
    "        \n",
    "        states = np.array([sample[0][0] for sample in mini_batch])\n",
    "        action = np.array([sample[1] for sample in mini_batch])\n",
    "        reward = np.array([sample[2] for sample in mini_batch])\n",
    "        next_states = np.array([sample[3][0] for sample in mini_batch])\n",
    "        dones = np.array([sample[4] for sample in mini_batch])\n",
    "        \n",
    "        #학습 파라미터\n",
    "        model_params = self.model.trainable_variables\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            #현재 상태에 대한 모델의 큐함수\n",
    "            predicts = self.model(states)\n",
    "            #실제로 한 행동이 1이고 나머지는 0인 원핫벡터를 사용\n",
    "            one_hot_action = tf.one_hot(action,self.action_size)\n",
    "            predicts = tf.reduce_sum(one_hot_action*predicts,axis=1)\n",
    "           \n",
    "        \n",
    "            #업데이트 target을 안정시키기 위해서\n",
    "            #다음 상태에 대한 타깃 모델의 큐함수\n",
    "            target_predicts = self.target_model(next_states)\n",
    "            #학습 도중 타깃 모델이 학습되는 일이 없게 tf.stop_gradient 적용\n",
    "            target_predicts = tf.stop_gradient(target_predicts)\n",
    "            \n",
    "            #벨만 최적 방정식을 이용한 업데이트 타깃\n",
    "            #큐함수 중 가장 큰 값\n",
    "            max_q = np.amax(target_predicts,axis=-1)\n",
    "            targets = reward + (1 - dones) * self.discount_factor *max_q\n",
    "            loss = tf.reduce_mean(tf.square(targets - predicts))\n",
    "        \n",
    "        #오류함수를 줄이는 방향으로 모델 업데이트\n",
    "        #업데이트하는 것은 타깃모델 x 현재모델임\n",
    "        grads =tape.gradient(loss,model_params)\n",
    "        self.optimizer.apply_gradients(zip(grads,model_params))\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # CartPole-v1 환경, 최대 타임스텝 수가 500\n",
    "    env = gym.make('CartPole-v1')\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "\n",
    "    # DQN 에이전트 생성\n",
    "    '''\n",
    "    1. state에 따른 action 선택\n",
    "    2. 선택한 action으로 environment에서 한 step 진행\n",
    "    3. environment로 부터 reward와 다음 state를 받음\n",
    "    4. sample을 리플레이에 저장\n",
    "    5.리플레이 메모리에서 무작위 추출한 sample로 학습\n",
    "    6.에피소드 마다 타깃 모델 업데이트    \n",
    "    \n",
    "    '''\n",
    "    agent = DQNAgent(state_size, action_size)\n",
    "    \n",
    "    \n",
    "\n",
    "    scores, episodes = [], []\n",
    "    score_avg = 0\n",
    "\n",
    "    num_episode = 300\n",
    "    for e in range(num_episode):\n",
    "        done = False\n",
    "        score = 0\n",
    "        # env 초기화\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "\n",
    "        while not done:\n",
    "            if agent.render:\n",
    "                env.render()\n",
    "\n",
    "            # 현재 상태로 행동을 선택\n",
    "            action = agent.get_action(state)\n",
    "            # 선택한 행동으로 환경에서 한 타임스텝 진행\n",
    "            #(4,) 에서 (1,4)로 모양 변경\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "            # 타임스텝마다 보상 0.1, 에피소드가 중간에 끝나면 -1 보상\n",
    "            score += reward\n",
    "            reward = 0.1 if not done or score == 500 else -1\n",
    "\n",
    "            # 리플레이 메모리에 샘플 <s, a, r, s'> 저장\n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            # 매 타임스텝마다 학습\n",
    "            if len(agent.memory) >= agent.train_start:\n",
    "                agent.train_model()\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                # 각 에피소드마다 타깃 모델을 모델의 가중치로 업데이트\n",
    "                agent.update_target_model()\n",
    "                # 에피소드마다 학습 결과 출력\n",
    "                score_avg = 0.9 * score_avg + 0.1 * score if score_avg != 0 else score\n",
    "                print(\"episode: {:3d} | score avg: {:3.2f} | memory length: {:4d} | epsilon: {:.4f}\".format(\n",
    "                      e, score_avg, len(agent.memory), agent.epsilon))\n",
    "\n",
    "                # 에피소드마다 학습 결과 그래프로 저장\n",
    "                scores.append(score_avg)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                #가로 에피소드\n",
    "                pylab.xlabel(\"episode\")\n",
    "                #세로 에피소드가 지속된 시간의 이동평균\n",
    "                pylab.ylabel(\"average score\")\n",
    "                pylab.savefig(\"./save_graph/graph.png\")\n",
    "\n",
    "                # 이동 평균이 400 이상일 때 종료\n",
    "                if score_avg > 300:\n",
    "                    agent.model.save_weights(\"./save_model/model\", save_format=\"tf\")\n",
    "                    sys.exit()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
